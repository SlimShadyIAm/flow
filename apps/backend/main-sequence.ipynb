{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the time of saccade vs. the length of a saccade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import (\n",
    "    DEGREES_PER_PIXEL,\n",
    "    TIMESTAMP_IDENT,\n",
    "    X_PIXELS,\n",
    "    Y_PIXELS,\n",
    "    Events,\n",
    "    extract_gaze_data_between_timestamps_proper,\n",
    "    get_participant_dominant_eye,\n",
    ")\n",
    "import json\n",
    "\n",
    "from velocityThreshold import detect_fix_ivt, find_sacc_from_fix\n",
    "\n",
    "EYE_TRACKER_FOLDER = \"eye_tracker_data/\"\n",
    "GAZE_DATA = []\n",
    "GAZE_DATA_BOOK = []\n",
    "GAZE_DATA_PAGE = []\n",
    "\n",
    "# participants that were told that they can change the settings beforehand\n",
    "participant_ids = [11]\n",
    "subquery = Events.select().where(Events.participant_id.in_(participant_ids))\n",
    "books = subquery.where(Events.event == \"OPEN_BOOK\")\n",
    "\n",
    "for participant in participant_ids:\n",
    "    for book in books:\n",
    "        START_TIME_BOOK = book.time\n",
    "        book_end = (\n",
    "            subquery.where(Events.event == \"CLOSE_BOOK\")\n",
    "            .where(Events.time > START_TIME_BOOK)\n",
    "            .get()\n",
    "        )\n",
    "        END_TIME_BOOK = book_end.time\n",
    "\n",
    "        # Get the events that have a timestamp less than the first CLOSE_BOOK event\n",
    "        events_book = subquery.where(Events.time <= END_TIME_BOOK)\n",
    "\n",
    "        formatted_time = datetime.fromtimestamp(START_TIME_BOOK / 1000).strftime(\n",
    "            \"%Y-%m-%d_%H-%M-%S\"\n",
    "        )\n",
    "        GAZE_FILE = f\"{EYE_TRACKER_FOLDER}[{participant}]-{formatted_time}.json\"\n",
    "        f = open(GAZE_FILE, \"r\")\n",
    "        GAZE_DATA_BOOK = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "        pages = (\n",
    "            subquery.where(Events.event == \"NEXT_PAGE\")\n",
    "            .where(Events.time > START_TIME_BOOK)\n",
    "            .where(Events.time < END_TIME_BOOK)\n",
    "        )\n",
    "        for page in pages:\n",
    "            START_TIME_PAGE = page.time\n",
    "            end_page = subquery.where(Events.event == \"NEXT_PAGE\").where(\n",
    "                Events.time > START_TIME_PAGE\n",
    "            )\n",
    "            if end_page.count() == 0:\n",
    "                continue\n",
    "            END_TIME_PAGE = (end_page.get()).time\n",
    "\n",
    "            # Get the gaze data for the page\n",
    "            GAZE_DATA_PAGE = extract_gaze_data_between_timestamps_proper(\n",
    "                GAZE_DATA_BOOK, START_TIME_PAGE, END_TIME_PAGE\n",
    "            )\n",
    "\n",
    "            # print(GAZE_DATA_PAGE)\n",
    "\n",
    "            timestamps = []\n",
    "            x = []\n",
    "            y = []\n",
    "\n",
    "            DOMINANT_EYE = get_participant_dominant_eye(participant)\n",
    "\n",
    "            # for each packet, plot the gaze point\n",
    "            for packet in GAZE_DATA_PAGE[\"data\"]:\n",
    "                if packet[f\"{DOMINANT_EYE}_gaze_point_validity\"] == 0:\n",
    "                    continue\n",
    "                x.append(\n",
    "                    (packet[f\"{DOMINANT_EYE}_gaze_point_on_display_area\"][0] * X_PIXELS)\n",
    "                    # * DEGREES_PER_PIXEL\n",
    "                )\n",
    "                y.append(\n",
    "                    (packet[f\"{DOMINANT_EYE}_gaze_point_on_display_area\"][1] * Y_PIXELS)\n",
    "                    # * DEGREES_PER_PIXEL\n",
    "                )\n",
    "                timestamps.append(packet[TIMESTAMP_IDENT])\n",
    "\n",
    "            df = pd.DataFrame({\"x\": x, \"y\": y, \"ts\": timestamps})\n",
    "            df = df.sort_values(by=\"ts\")\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            df[\"x\"] = df[\"x\"] * DEGREES_PER_PIXEL\n",
    "            df[\"y\"] = df[\"y\"] * DEGREES_PER_PIXEL\n",
    "            df[\"ts\"] = df[\"ts\"] / 1_000_000\n",
    "\n",
    "            # display(df)\n",
    "            SACCADIC_THRESHOLD = 80\n",
    "            # Plot fixations\n",
    "            fixations, v, labels = detect_fix_ivt(df, sacvel=SACCADIC_THRESHOLD)\n",
    "            saccades = find_sacc_from_fix(fixations)\n",
    "            # print(saccades)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(X_PIXELS / 100, Y_PIXELS / 100))\n",
    "            # Make x axis go from 0 to 50\n",
    "            # ax.set_xlim(0, 50)\n",
    "            ax.set_ylim(0, 0.1)\n",
    "\n",
    "            ax.set_title('Main Sequence')\n",
    "            p = ax.scatter(\n",
    "                saccades[\"dxy\"],\n",
    "                saccades[\"len\"],\n",
    "                c=saccades[\"ts\"],\n",
    "                s=40,\n",
    "                cmap=\"plasma\",\n",
    "                label=f\"Participant {participant} - {book.new_value}\",\n",
    "            )\n",
    "\n",
    "\n",
    "            # Make trendline\n",
    "            z = np.polyfit(saccades[\"dxy\"], saccades[\"len\"], 1)\n",
    "            p = np.poly1d(z)\n",
    "            # Label with equation\n",
    "            plt.plot(saccades[\"dxy\"], p(saccades[\"dxy\"]), \"r--\", label=\"f(x) = %.6fx + %.6f\"%(z[0],z[1]))\n",
    "\n",
    "            ax.set_xlabel(\"Distance (degrees)\")\n",
    "            ax.set_ylabel(\"Duration (seconds)\")\n",
    "            ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n",
      "/Users/idk/repos/flow/apps/backend/velocityThreshold.py:62: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rho = cov[0,1] / (sx*sy)\n"
     ]
    }
   ],
   "source": [
    "# Get the average for each page fitted linear model of the main sequences of a participant\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import (\n",
    "    DEGREES_PER_PIXEL,\n",
    "    TIMESTAMP_IDENT,\n",
    "    X_PIXELS,\n",
    "    Y_PIXELS,\n",
    "    Events,\n",
    "    extract_gaze_data_between_timestamps_proper,\n",
    "    get_participant_dominant_eye,\n",
    ")\n",
    "import json\n",
    "\n",
    "\n",
    "from velocityThreshold import detect_fix_ivt, find_sacc_from_fix\n",
    "\n",
    "EYE_TRACKER_FOLDER = \"eye_tracker_data/\"\n",
    "GAZE_DATA = []\n",
    "GAZE_DATA_BOOK = []\n",
    "GAZE_DATA_PAGE = []\n",
    "\n",
    "# participants that were told that they can change the settings beforehand\n",
    "participant_ids = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "subquery = Events.select().where(Events.participant_id.in_(participant_ids))\n",
    "books = subquery.where(\n",
    "    (Events.event == \"OPEN_BOOK\") & (Events.new_value != \"Smart Farming Tech - \")\n",
    ")\n",
    "\n",
    "for book in books:\n",
    "    START_TIME_BOOK = book.time\n",
    "    book_end = (\n",
    "        subquery.where(Events.event == \"CLOSE_BOOK\")\n",
    "        .where(Events.time > START_TIME_BOOK)\n",
    "        .get()\n",
    "    )\n",
    "    END_TIME_BOOK = book_end.time\n",
    "\n",
    "    # Get the events that have a timestamp less than the first CLOSE_BOOK event\n",
    "    events_book = subquery.where(Events.time <= END_TIME_BOOK)\n",
    "\n",
    "    # Read from participants.json whether or not the participant has low resolution data\n",
    "    # These we should not divide the timestamp with 1000\n",
    "\n",
    "    LOW_RES = json.load(open(\"participants.json\", \"r\"))[f\"{book.participant_id}\"][\n",
    "        \"low_resolution\"\n",
    "    ]\n",
    "    if LOW_RES:  # TODO: use the estimate from the stdev\n",
    "        continue\n",
    "\n",
    "    if not LOW_RES:\n",
    "        START_TIME_BOOK /= 1000\n",
    "    formatted_time = datetime.fromtimestamp(START_TIME_BOOK).strftime(\n",
    "        \"%Y-%m-%d_%H-%M-%S\"\n",
    "    )\n",
    "    GAZE_FILE = f\"{EYE_TRACKER_FOLDER}[{book.participant_id}]-{formatted_time}.json\"\n",
    "    f = open(GAZE_FILE, \"r\")\n",
    "    GAZE_DATA_BOOK = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    DOMINANT_EYE = get_participant_dominant_eye(book.participant_id)\n",
    "\n",
    "    pages = subquery.where(Events.event == \"NEXT_PAGE\").where(\n",
    "        (Events.time > START_TIME_BOOK) & (Events.time < END_TIME_BOOK)\n",
    "    )\n",
    "    for page in pages:\n",
    "        START_TIME_PAGE = page.time\n",
    "        end_page = subquery.where(Events.event == \"NEXT_PAGE\").where(\n",
    "            Events.time > START_TIME_PAGE\n",
    "        )\n",
    "        if end_page.count() == 0:\n",
    "            continue\n",
    "        END_TIME_PAGE = (end_page.get()).time\n",
    "\n",
    "        # Get the gaze data for the page\n",
    "        GAZE_DATA_PAGE = extract_gaze_data_between_timestamps_proper(\n",
    "            GAZE_DATA_BOOK, START_TIME_PAGE, END_TIME_PAGE\n",
    "        )\n",
    "\n",
    "        # print(GAZE_DATA_PAGE)\n",
    "\n",
    "        timestamps = []\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        # for each packet, plot the gaze point\n",
    "        for packet in GAZE_DATA_PAGE[\"data\"]:\n",
    "            if packet[f\"{DOMINANT_EYE}_gaze_point_validity\"] == 0:\n",
    "                continue\n",
    "            x.append(\n",
    "                (packet[f\"{DOMINANT_EYE}_gaze_point_on_display_area\"][0] * X_PIXELS)\n",
    "                # * DEGREES_PER_PIXEL\n",
    "            )\n",
    "            y.append(\n",
    "                (packet[f\"{DOMINANT_EYE}_gaze_point_on_display_area\"][1] * Y_PIXELS)\n",
    "                # * DEGREES_PER_PIXEL\n",
    "            )\n",
    "            timestamps.append(packet[TIMESTAMP_IDENT])\n",
    "\n",
    "        df = pd.DataFrame({\"x\": x, \"y\": y, \"ts\": timestamps})\n",
    "        df = df.sort_values(by=\"ts\")\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        df[\"x\"] = df[\"x\"] * DEGREES_PER_PIXEL\n",
    "        df[\"y\"] = df[\"y\"] * DEGREES_PER_PIXEL\n",
    "        df[\"ts\"] = df[\"ts\"] / 1_000_000\n",
    "\n",
    "        # display(df)\n",
    "        SACCADIC_THRESHOLD = 80\n",
    "        # Plot fixations\n",
    "        fixations, v, labels = detect_fix_ivt(df, sacvel=SACCADIC_THRESHOLD)\n",
    "        saccades = find_sacc_from_fix(fixations)\n",
    "\n",
    "        z = np.polyfit(saccades[\"dxy\"], saccades[\"len\"], 1)\n",
    "        p = np.poly1d(z)\n",
    "\n",
    "        # Continue from here by saving the 1 dimensional (linear) polyfit into a map or something\n",
    "        # and then averaging them on a book and participant basis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-anal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
